---
title: "Bayesian Navigation in Westminster"
author: "Agnes Coaker"
date: "04/12/2021"
output: pdf_document
---

## Introduction

In navigation, notably in the military, 'position resection' involves deducing your geographic location by observing how it relates to three or more known locations/landmarks around you. Specifically, one calculates the bearing (an angle measured clockwise from north) between their location and a landmark. These bearings are then drawn on a map, however instead of intersecting, they draw a triangle of some size. The observer is likely to be in, or near, the triangle, depending on the amount of error in the measurement.

So where can we predict the observer to be? Without more analysis, the most we can say is that they are likely to be in the triangle. For many uses, certainly for the military, this rough location will suffice. In fact, there is not an equal chance of being anywhere in the triangle, nor is the observer necessarily most likely to be in the very centre. Instead, this is affected by the distance from the observer to each landmark, as the closer a landmark, the less error there is likely to be in the measurement of the bearing.

![image from Ordinance Survey, demonstrating the concept ^1^](find-location-compass2.jpg)

In this report we will attempt to deduce a more precise location for the observer based on bearings and other knowledge we may have. Bayesian inference combines pre-existing knowledge of a parameter(s) (using a prior distribution(s)) with observations, in order to guide statistical inference about a problem. The output of this is a 'posterior distribution(s)' which combines pre-existing knowledge/assumptions and observations to accurately describe outcomes. 

This situation, with its possibilities for various pieces of prior knowledge is a good example in which we can apple Bayesian inference to deduce where our observer is most likely to be. Intuitively, consider someone taking their bearings atop a rock stack or on a road and, knowing this, being able to find their precise position within the triangle using their map.

In our report, we consider an example where we have no prior knowledge, and where we do have some prior knowledge like this. In both cases the end result will be a map plotting a sample of the 'posterior distribution', showing where our observer is likely to be based on all this information. The map made using prior knowledge should be more precise and correct than the map made without it.

## Methodology
### Utilising Prior Knowledge in Bayesian Inference

Mathematically speaking, we cannot have no prior knowledge at all. We need some probability distribution to form the starting point for our analysis. Instead, the least informative prior knowledge we can have is that there is an equal likelihood of the observer being anywhere in the rough region around their observation. We achieve this using the Uniform distribution when defining our statistical model.

When we have this 'prior distribution', we work to derive the 'posterior distribution' using observed data. At an analytical level, for a parameter of interest $\theta$, this is done by expanding Bayes' theorem using an integral.

$$p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}=\frac{p(D|\theta)p(\theta)}{\int{p(D|\theta)p(\theta)d\theta}}$$
Here: $p(\theta)$ is the prior distribution of pre-existing knowledge, $D$ is an observed dataset and $p(\theta|D)$ is the posterior distribution (intuitively, the updated probability of our parameter based on the observed data). In order to calculate this, we need $p(D|\theta)$, which is the likelihood.

However, for more complex models, the integrals involved become prohibitively difficult and preclude analytical solutions. One way around this is to use the principle of 'conjugacy' which relies on selecting a family of distributions which is conjugate to the likelihood and which allow for far quicker computation. For example, for a model with a binomial likelihood $p(D|\theta)=Bi(k|\theta,n)$, if we use a beta prior distribution $p(\theta)=Be(\alpha,\beta)$, we can show the posterior distribution to be $p(\theta|D)\propto Be(\alpha+k,\beta+n-k)$. But only a few simple models allow for the use of conjugate priors, and their restrictive nature can run against the actual prior knowledge we have. Instead, we can opt to use sample based approximation.

The most widely used methods for this are Markov Chain Monte Carlo (MCMC) methods. These generate correlated chains from a target density using Markov chains. We set the target density to be that of our posterior distribution for Bayesian Analysis. The underlying principle of Markov chains is that they extend a single experiment to a chain of experiments  where for $X_1,...,X_n,...$:

$$p(X_n=x_n|X_1=x_1,...,X_{n-1}=x_{n-1})=p(X_n=x_n|X_{n-1}=x_{n-1})$$

We select $X_0$ randomly from a starting distribution (our prior distribution) and the each successive value $X_i$ is generated by the transition probability $P_{X_{i}|X_{i-1}}$, which is constructed so that the chain converges to a unique stationary distribution (the target distribution). For our purposes we set that to be the posterior distribution. When using the samples from this, we skip the initial part of the simulation (the 'burn in'), and only use those samples from the section after the chain converged.

### The Metropolis-Hasting Algorithm

The Metropolis-Hasting algorithm is a commonly used MCMC method that does this. Without going through the formal algorithm, the intuitive idea for selecting each step of a chain is deciding whether or not a proposed value is under or over represented in the chain given the target distribution.

For each step in the chain, we generate a possible value for the next step using a 'proposal distribution'. This is typically the normal distribution, centred around the previous step's value.

Consider potential sample $\theta^*$ generated by the proposal distribution, it is close to the previous sample $\theta^{i-1}$. If $p(\theta^*)>p(\theta^{i-1})$ in the target distribution then we want more $\theta^*$ values in the sample than $\theta^{i-1}$ values. Therefore we set $\theta^i=\theta^*$. However if this is not the case, we must made a decision by comparing the two probabilities using an acceptance ratio.

$$r=\frac{h(\theta^*)q(\theta^{i-1}|\theta^*)}{h(\theta^{i-1})q(\theta^*|\theta^{i-1})}$$
Where $h$ is the target distribution and $q$ is the proposal distribution. This will give $0<r\leq1$, thus for every instance of $\theta^{i-1}$ we should have $r$ instances of $\theta^*$. So we set $\theta^i=\theta^*$ with a probability of $r$ (i.e. we set $\theta^i=\theta^{i-1}$ with a probability of $1-r$). In practice we randomly draw $u$ from $[0,1]$ and if $u<r$ we set $\theta^i=\theta^*$ and if $u\geq r$ we set $\theta^i=\theta^{i-1}$.

This acceptance ratio $r$ is a very useful expression for Bayesian inference because it allows for a drastic simplification. For the target distribution, i.e. the posterior distribution, we can use just the product of the prior and likelihood densities ($p(D|\theta)p(\theta)$). This is because the normalising constant will cancel out in the acceptance ratio, thus there is no need to evaluate the normalising integral.

In the case that the proposal distribution is symmetric (e.g. if we propose the next step of the chain using the Normal distribution), we can drop the 'Hastings' correction' and just use the Metropolis algorithm, which removes the proposal distribution from the acceptance ratio. In that case the acceptance ratio becomes:

$$r=\frac{h(\theta^*)}{h(\theta^{i-1})}=\frac{prior(\theta^*)likelihood(\theta^*)}{prior(\theta^{i-1})likelihood(\theta^{i-1})}$$
One potential issue to this is that the denominator may be computed to equal zero. Although these values are not truly zero, they may be too small to compute as anything else. A modification which may solve this is using the loglikelihood and logprior instead. In this case multiplication and division of the acceptance ratio is replaced with addition and subtraction leaving:

$$r=logprior(\theta^*)+loglikelihood(\theta^*)-logprior(\theta^{i-1})-loglikelihood(\theta^{i-1})$$
We would also have to compare this acceptance ratio to a reasonable figure, so would make a decision about acceptance based on $log(u)<r$.

One of the main challenges of the Metropolis-Hasting/Metropolis algorithm is ensuring that it converges in a reasonable time-frame. The algorithm will always converge to the target distribution, regardless of the proposal distribution used, but achieving that without days of computing can be challenging.


### Monitoring Convergence

The simplest way to monitor convergence is to plot the chains that are generated by the algorithm, to see how well they are mixing within the parameter space. Once a chain has converged it will be stationary, meaning it will have no trend and constant variance. When plotting chains (iterations on the x-axis and values on the y-axis) we generate 'traceplots'. We can visually confirm convergence using these. They should sit in the same range, not trend up or down and have constant variance. A more mathematical assessment is the Gelman-Rubin statistic which analyses the difference between multiple Markov chains. 

This statistic compares the variance between and within chains. It gives the Potential Scale Reduction Factor (PSRF) $\hat{R}$, when this is high, typically more than 1.1 or 1.2, the chains need to be run for longer to improve convergence. In order to calculate a PSFR value we need to run multiple chains per parameter, typically three or four.

In our case we have three parameters, we need to calculate the PSFR for each parameter, and run our chains until all of the PSFR statistics are small enough. If we were struggling to show our chains has converged using the Gelman-Rubin statistic, we may choose to disregard it and instead make a choice based on the appearance of the chains when plotted.

Although not a direct monitor of convergence, another statistic to monitor is the acceptance rate. This is proportion of proposed samples that are accepted, if the acceptance rate is too low or too high, convergence will take longer. If it is too high, too many of the proposed sample values are being accepted, and vice-versa if it is too low. The ideal acceptance rate is not a precise science but a good rate is typically considered 20 - 35. Acceptance rates can be effected by changing the variance/covariance of the proposal distribution.

```{r img-with-knitr, echo=FALSE, fig.align='center', out.width='50%'}
knitr::include_graphics("acceptance-rates-flowchart.jpg")
```

### Defining our Model with an Uniform Prior

Returning to our specific example, in which we try to determine the a more precise location of our observer. The parameters of interest are latitude ($\lambda$) and longitude ($\phi$). We also do not know how much error was introduced when taking the bearings, for example by how precise the compass was, so instead of estimating this we introduce the standard deviation as a third parameter $\sigma$. 

As discussed earlier, our prior distribution for the location will use Uniform distributions, one for latitude and one for longitude. For the standard deviation $\sigma$ we use an Exponential distribution, which makes the assumption that the error in measurement is small. To generate a single prior distribution we combine these three distributions, either by multiplying them for a prior distribution, or by summing their logs for a logprior distribution.

We record our observed dataset and the three bearing angles as $\alpha$, $\beta$ and $\gamma$. We store the known locations for the landmarks these were taken from as $((\lambda_1,\phi_1),(\lambda_2,\phi_2),(\lambda_3,\phi_3))$. The next step is to define a likelihood, which we will need to derive sample values. To define this likelihood, we must be able to calculate the bearing between a given value and one of our known locations. We create a function to do this $B(P1,P2)$ which find the bearing from $P1$ to $P2$.

The likelihood will describe how likely it is that the bearings observed arose from a sample latitude and longitude $(\lambda,\phi)$ against a recorded landmark location. We assume a normal error for these measurements because of the Central Limit Theorem: there are simply too many possible sources of fluctuation and error to do otherwise. We also assume the same variance for each bearing, i.e. assuming some kind of consistent measurement error.

$$p(D|\theta)=N(\alpha|B((\lambda,\phi),(\lambda_1,\phi_1)),\sigma^2)*N(\beta|B((\lambda,\phi),(\lambda_2,\phi_2)),\sigma^2)*N(\gamma|B((\lambda,\phi),(\lambda_3,\phi_3)),\sigma^2)$$
The initial value we propose to the Metropolis-Hasting algorithm $X_0$ will not effect the ultimate convergence of the chains, but will effect how fast it happens. In order to increase the speed of convergence, we must start with a point likely to be close to the observation. Therefore we find the intersection of two bearing lines and draw initial samples from a small uniform distribution $\pm0.01$ around the latitude and longitude values of this intersection. For $\sigma$ we draw a random value from the prior exponential distribution chosen. Any exact values used will be discussed in the results.

The final thing we need to define is the proposal distribution, again this will not effect ultimate convergence but can speed it up. This typically uses the normal distribution, using the previous sample value as the mean and a pre-defined variance. In the case of multiple parameters $(\lambda, \phi, \sigma)$ we can use the multivariate normal distribution and use an arbitarary covariance matrix to being with, before adjusting it for best fit and performance.

However we cannot simply use the multivariate normal for the proposal distribution in our model because it could generate values that we could not use. In particular, we use it to propose a value for the standard deviation which must be $>0$ bute it offers no way to limit the samples drawn to a particular range. If the previous sample of variance is small (which is very possible given out prior distribution), it becomes more likely that the sample drawn will be negative. In order to avoid this, we re-draw proposals if $\sigma<0$. However by doing so, we are no longer using the multivariate normal, but rather the truncated multivariate normal ($tmvnorm$), which is not symmetric and which will require Hastings' correction to include the proposal distribution in the acceptance ratio.

$$r=logprior(\theta^*)+loglikelihood(\theta^*)+logtmvnorm(\theta^{i-1}|\theta^*) \newline -logprior(\theta^{i-1})-loglikelihood(\theta^{i-1})-logtmvnorm(\theta^*|\theta^{i-1})$$

### Defining our Model with a Different Prior

As discussed in the introduction, we can use other pre-existing knowledge in our Bayesian inference by introducing it in our prior distribution. In this report we will consider the case that the observer takes their bearings while standing on a road. We define a function $\rho(\lambda,\phi)$ which tells us how close we are to a road and use that in our new prior distribution. As before, we will generate the logprior by summing the logs of the distributions for each different parameter. We will continue to use $Expo(20)$ for $\sigma$ but this time we will incorporate $\rho$ into the distribution for the latitude and longitude.

We know we are on a road but not exactly how close we are to its centre on the map, and this will be effected by several factors, including error in the maps. Therefore by virtue of the Central Limit Theorem we will use the Normal distribution. As we know the observer is standing on the road, we set our mean to equal a distance of zero. For our variance we use $6^2$ which makes roughly intuitive sense when you consider the average size of a road. From our observed data we generate a distance to the nearest road and use this to find the density. This makes out total logprior:

$$p(\theta)=log(N(\rho(\lambda,\phi)|0,6^2)) + log(Expo(\sigma|20))$$

Briefly considering the other components of our model: the likelihood will remain the same, it measures the likelihood of a sample latitude and longitude arising given the observed bearings we have, this has not changed. The proposal distribution also remains static (unless it causes computation issues) because it has no effect on final convergence. Finally the initial value for the Metropolis-Hasting algorithm can also remain the same as a bearing intersection remains a good 'first guess'.


## Results

### Using a Uniform Prior

```{r code_setup, include=FALSE}
library(REdaS)
library(ggmap)
library(mvtnorm)
library(tmvtnorm)
library(coda)
library(MASS)
library(reshape2)
library(osmar)
library(osmdata)
library(sf)
library(geosphere)
set.seed(123)

#set reference points & bearings Nelson's column, London eye and Big ben
landmarks<-data.frame(lon=c(-0.12790934620440858, -0.11964167814801072,
                            -0.1245496367169894),
                      lat=c(51.50779711415662, 51.50345826867559, 
                            51.5008340546969))
landmarks_named<-data.frame(landmarks=c("Nelson's Column","London Eye", "Big Ben"),bearings=c(18.14,105.04,246.43), landmarks)
alpha <- 18.14
beta <- 105.04
gamma <- 146.43
bearing_360 <- function(p1,p2) {
  thetah <- atan2(as.numeric(p2[1])-p1[1],as.numeric(p2[2])-p1[2])
  if (thetah>=0) {
    return(rad2deg(thetah))
  } else {
    return(rad2deg(thetah+2*pi))
  }
}
loglikelihood <- function (params) {
  point <- params[1:2]
  sigma <- params[3]
  dnorm(alpha, mean=bearing_360(point, landmarks[1,]),sd=sigma, log=T) +
    dnorm(beta, mean=bearing_360(point, landmarks[2,]),sd=sigma, log=T) +
    dnorm(gamma, mean=bearing_360(point, landmarks[3,]),sd=sigma, log=T)
}
logprior <- function (params) {
  theta <- params[1]
  lambda <- params[2]
  sigma <- params[3]
  dunif(theta, -0.5, 0, log=T) + dunif(lambda, 51.25, 51.75, log=T) + 
    dexp(sigma, 20, log=T)
}
prop.cov <- c(1e-8,1e-8,1e-4)*diag(3)
```

For our specific example, we consider a case where a civil servant gets lost inside their labyrinthine office and attempts to deduce their location by taking bearings of the landmarks visible through the windows around them. The three locations chose are Nelson's column, the London Eye and Big Ben. The relevant data on these is store below.
```{r show-landmarks, echo=FALSE}
head(landmarks_named)
```

These observed points and bearings generate the following triangle when plotted on a map.

```{r rough_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width='70%'}
d <- seq(0, 0.4, 0.0001)
line1 <- data.frame(lon=landmarks[1,1] + d*sin(alpha*pi/180+pi),
                    lat=landmarks[1,2] + d*cos(alpha*pi/180+pi))
line2 <- data.frame(lon=landmarks[2,1] + d*sin(beta*pi/180+pi),
                    lat=landmarks[2,2] + d*cos(beta*pi/180+pi))
line3 <- data.frame(lon=landmarks[3,1] + d*sin(gamma*pi/180+pi),
                    lat=landmarks[3,2] + d*cos(gamma*pi/180+pi))
register_google(key="AIzaSyDG_GUhJvpvO4DeYu5KDSu0EulqQFlla_o",write=TRUE)
map <- get_map(c(-0.1257,51.5045),zoom=16,maptype="roadmap")
bearingsPlot <- ggmap(map)+
  geom_point(aes(x = lon, y = lat), size = 1, data = landmarks, alpha = .5) +
  geom_line(aes(x=lon,y=lat),data=line1) +
  geom_line(aes(x=lon,y=lat),data=line2) +
  geom_line(aes(x=lon,y=lat),data=line3)
bearingsPlot
```

As discussed in the methodology, we will first use a reasonably wide uniform prior for the latitude and longitude. Specicially we use [-0.5,0] for the longitude and [51.25,51.75] for the latitude. For the exponential distribution for $\sigma$ we use $\lambda=20$. This was chosen because it assumes a small error, with mean of $\frac{1}{20}=0.5$.We sum these to generate the logprior which is specific to this example.

We will also initialise the Metropolis-Hasting sampler carefully using an intersection of two bearing lines, choosing those whose intersection sits nearest to the closest landmark. This is shown in the plot below as a red dot, at the intersection closest to Nelson's column, sitting within the Admiralty Arch.

```{r close_plot, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width='70%'}
zoom_map <- get_map(c(-0.128,51.5065),zoom=18,maptype="roadmap")
bearingsPlot <- ggmap(zoom_map)+
  geom_point(aes(x = lon, y = lat), size = 1, data = landmarks, alpha = .5) +
  geom_line(aes(x=lon,y=lat),data=line1) +
  geom_line(aes(x=lon,y=lat),data=line2) +
  geom_line(aes(x=lon,y=lat),data=line3)
intersectBearings <- function(p1,b1,p2,b2) {
  x1 <- p1[1]
  x2 <- p1[1] + 0.1*sin(b1*pi/180)
  x3 <- p2[1]
  x4 <- p2[1] + 0.1*sin(b2*pi/180)
  y1 <- p1[2]
  y2 <- p1[2] + 0.1*cos(b1*pi/180)
  y3 <- p2[2]
  y4 <- p2[2] + 0.1*cos(b2*pi/180)
  x <- ((x1*y2-y1*x2)*(x3-x4)-(x1-x2)*(x3*y4-y3*x4))/((x1-x2)*(y3-y4)-(y1-y2)*(x3-x4))
  y <- ((x1*y2-y1*x2)*(y3-y4)-(y1-y2)*(x3*y4-y3*x4))/((x1-x2)*(y3-y4)-(y1-y2)*(x3-x4))
  return(as.numeric(c(x,y)))
}
intersection <- intersectBearings(landmarks[1,],alpha,landmarks[3,],gamma)
bearingsPlot + geom_point(aes(intersection[1], intersection[2], colour='green')) +
  theme(legend.position = 'none')
```
For the likelihood function, we need only input our bearings and landmark coordinates as recorded above. We can then choose initial parameter samples from the small range around the intersection plotted above for $\lambda$ and $\phi$, and select random values from $Expo(20)$ for $\sigma$.

We set our proposal distribution to be the truncated multivariate distribution as described in the methodology. For the covariance matrix we use the below which has been adjusted to provide quick convergence and good acceptance rates.
```{r show-cov, echo=FALSE}
prop.cov
```

We initially run the Metropolis-Hasting algorithm for three chains for each of the parameters over 10,000 iterations (in an attempt to move past burn in) before we begin calculating the Gelman-Rubin statistic for each parameter. When it is less than 1.2 for all parameters we stop the loop and record the final sample values achieved.

```{r convergence-chains, echo=FALSE, fig.height = 6}
#use this to generate draw with a sensible start
#dimensions are iteration index, parameter, chain
#parameters are ordered lambda, theta, sigma
draws <- array(0,dim=c(50000,3,3))
draws[50000,1,] <- runif(3,intersection[1]-0.01, intersection[1]+0.01)
draws[50000,2,] <- runif(3,intersection[2]-0.01, intersection[2]+0.01)
draws[50000,3,] <- rexp(3,20)

#evaluate posterior by sampling using M-H algorithm
converged <- FALSE
step <- 2
accepted <- rep(1,3)
while (!all(converged)) {
  draws[1,,] <- draws[50000,,]
  for (chain in 1:3) {
    proposed <- c(0,0,-1)
    while (proposed[3] < 0) {
      proposed <- rmvnorm(1,draws[step-1,,chain],prop.cov)
    }
    r <- loglikelihood(proposed) + 
      logprior(proposed) +
      dtmvnorm(x=draws[step-1,,chain], mean=c(proposed), sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T) -
      loglikelihood(draws[step-1,,chain]) - 
      logprior(draws[step-1,,chain]) -
      dtmvnorm(x=proposed, mean=draws[step-1,,chain], sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T)
    a <- min(0,r)
    u <- runif(1)
    if (log(u) < a) {
      draws[step,,chain] <- proposed
      accepted[chain] <- accepted[chain]+1
    } else {
      draws[step,,chain] <- draws[step-1,,chain]
    }
  }
  step <- step + 1
  if (step > 10000) {
    chainlist <- mcmc.list(Chain1=mcmc(draws[,,1]),
                           Chain2=mcmc(draws[,,2]),
                           Chain3=mcmc(draws[,,3]))
    converged <- all((gelman.diag(chainlist)$psrf[,2])<1.2)
  }
}

#plot these chains visually to confirm convergence
par(mfrow=c(3,1))
min_lamda=min(draws[1:(step-2),1,])
max_lambda=max(draws[1:(step-2),1,])
plot(1:(step-2),draws[1:(step-2),1,1],type="l",col=2,
     ylim=c(min_lamda,max_lambda), main="Traceplots of Longitude",
     xlab="Iteration", ylab="Longitude Sample")
lines(x=1:(step-2),y=draws[1:(step-2),1,2],col=3)
lines(1:(step-2),draws[1:(step-2),1,3],col=4)
min_phi=min(draws[1:(step-2),2,])
max_phi=max(draws[1:(step-2),2,])
plot(1:(step-2),draws[1:(step-2),2,1],type="l",col=2,
     ylim=c(min_phi,max_phi), main="Traceplots of Latitude",
     xlab="Iteration", ylab="Latitude Sample")
lines(1:(step-2),draws[1:(step-2),2,2],col=3)
lines(1:(step-2),draws[1:(step-2),2,3],col=4)
min_sigma=min(draws[1:(step-2),3,])
max_sigma=max(draws[1:(step-2),3,])
plot(1:(step-2),draws[1:(step-2),3,1],type="l",col=2,
     ylim=c(min_sigma,max_sigma), main="Traceplots of Standard Deviation",
     xlab="Iteration", ylab="SD Sample")
lines(1:(step-2),draws[1:(step-2),3,2],col=3)
lines(1:(step-2),draws[1:(step-2),3,3],col=4)
```
The chains should have mostly converged because all parameters have a Gleman-Rubin statistic of $<1.2$ but we should still confirm convergence visually. In these traceplots we can see how the latitude and longitude converge 'quickly' at around 1000 steps. Meanwhile the variance is far slower to achieve any sort of convergence, and the state it does ultimately reach a stationary state with constant variance, the variance within and between the chains is still quite high. Ultimately it does meet the criteria for convergence both visually and via Gelman-Rubin.

Using the final sample values achieved as our new initial value, we run the same Metropolis-Hasting algorithm for 25,000 iterations (with the same logprior/ loglikelihood/ truncated multivariate normal proposal distributions etc.). After this has completed we can review the acceptance rates and monitor them, mainly to understand if the covariance matrix of the proposal distribution needs to be adjusted although for the graphs shown that has been done already. A low acceptance rate could also indicate a problem with algorithm implementation as there are several changes to made when using logprior & loglikelihood which could lower acceptance rates if not made correctly.

We can finally confirm all our parameters have converged by checking the traceplots of the chains which should have eliminated the burn in by only starting after burn in. These are shown below.

```{r sample-chains, echo=FALSE, fig.height = 6}
sample <- array(0,dim=c(25000,3,3))
sample[1,,] <- draws[step-2,,]
accepted <- rep(1,3)
for (step in 2:25000) {
  for (chain in 1:3) {
    proposed <- c(0,0,-1)
    while (proposed[3] < 0) {
      proposed <- rmvnorm(1,sample[step-1,,chain],prop.cov)
    }
    r <- loglikelihood(proposed) + 
      logprior(proposed) +
      dtmvnorm(x=sample[step-1,,chain], mean=c(proposed), sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T) -
      loglikelihood(sample[step-1,,chain]) - 
      logprior(sample[step-1,,chain]) -
      dtmvnorm(x=proposed, mean=sample[step-1,,chain], sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T)
    a <- min(0,r)
    u <- runif(1)
    if (log(u) < a) {
      sample[step,,chain] <- proposed
      accepted[chain] <- accepted[chain]+1
    } else {
      sample[step,,chain] <- sample[step-1,,chain]
    }
  }
}
par(mfrow=c(3,1))
min_lambda=min(sample[1:(step-1),1,])
max_lambda=max(sample[1:(step-1),1,])
plot(1:(step-1),sample[1:(step-1),1,1],type="l",col=2,
     ylim=c(min_lambda,max_lambda), main="Traceplots of Longitude",
     xlab="Iteration", ylab="Longitude Sample")
lines(1:(step-1),sample[1:(step-1),1,2],col=3)
lines(1:(step-1),sample[1:(step-1),1,3],col=4)
min_phi=min(sample[1:(step-1),2,])
max_phi=max(sample[1:(step-1),2,])
plot(1:(step-1),sample[1:(step-1),2,1],type="l",col=2,
     ylim=c(min_phi,max_phi), main="Traceplots of Latitude",
     xlab="Iteration", ylab="Latitude Sample")
lines(1:(step-1),sample[1:(step-1),2,2],col=3)
lines(1:(step-1),sample[1:(step-1),2,3],col=4)
min_sigma=min(sample[1:(step-1),3,])
max_sigma=max(sample[1:(step-1),3,])
plot(1:(step-1),sample[1:(step-1),3,1],type="l",col=2,
     ylim=c(min_sigma,max_sigma), main="Traceplots of Standard Deviation",
     xlab="Iteration", ylab="SD Sample")
lines(1:(step-1),sample[1:(step-1),3,2],col=3)
lines(1:(step-1),sample[1:(step-1),3,3],col=4)
```
The traceplots of latitude and longitude are clearly stationary with constant variance and show values that look to be correctly in the triangular area we are expecting. Meanwhile the traceplot of the standard deviation shows far more variance and bad mixing between the chains.

The ultimate outputs of interest for our problem are the latitude and longitude. If we were interested in, say, knowing the error of a specific compass, we could spend more time adjusting parameters to get a better estimate of $\sigma$ but given the chance that that algorithm may take longer to run than it is possible on this computer, it would not be an efficient choice for this problem.

We are now confident that we have sampled correctly from our posterior distribution and can examine our results. Before we plot the actual locations, we will look at histograms of the samples. These indicate a slightly non-symmetrical distribution. Intuitively this does make sense, as mentioned in the introduction, the probability of an observer's location within the triangle is effected by the three bearings, with those taken from closer landmarks having more weight. Essentially: our posterior distribution density is pulled in three directions, but against only two axes, giving rise to non-symmetrical distributions.

```{r hists, include=FALSE}
par(mfrow=c(1,2))
hist(sample[,1,], main="Histogram of Longitude", xlab="Value", ylab="")
hist(sample[,2,], main="Histogram of Latitude", xlab="Value", ylab="")
```

Finally for this model, we can plot the samples of latitude and longitude together on a map to show our estimated position based on a uniform prior distribution. The density of samples is shown by the density of the blue fill, while the mean of the samples is shown by the red dot. The closest landmark is Nelson's column, being significantly closer than the other two, meaning the sample centering on the bearing from this landmark is expected and confirms the validity of our model.

```{r map-plot, echo=FALSE, warning=FALSE, message=FALSE}
D <- kde2d(as.vector(sample[,1,]),as.vector(sample[,2,]),
           h=c(sd(sample[,1,]),sd(sample[,2,])),
           n=1024,
           lims=c(-0.14,-0.12,51.504,51.507)) # Enough to cover map
z <- melt(D$z)
z$Var1<-D$x[z$Var1]
z$Var2<-D$y[z$Var2]
map <- get_map(c(mean(sample[,1,]),mean(sample[,2,])),zoom=18,maptype="road")
mapPoints <- ggmap(map)+
  geom_point(aes(x = lon, y = lat), size = 1, data = landmarks, alpha = .5) +
  geom_raster(data=z,aes(x=Var1,y=Var2,fill=value))+
  guides(fill=FALSE,alpha=FALSE)+
  scale_fill_gradientn(colours=c("#0000FF00","#0000FFFF"))+
  coord_cartesian() +
  geom_line(aes(x=lon,y=lat),data=line1) +
  geom_line(aes(x=lon,y=lat),data=line2) +
  geom_line(aes(x=lon,y=lat),data=line3)+
  geom_point(aes(x=lon,y=lat),
             data=data.frame(lon=mean(sample[,1,]),lat=mean(sample[,2,])),
             size=0.5,colour="#FF0000")
mapPoints
```

### Using a Different Prior

```{r roads-setup, include=FALSE}
#now changing our prior and assuming proximity to a road
#setting up the distance to a road function and using it in the logprior func
roads_box <- center_bbox(center_lon=intersection[1],
                         center_lat=intersection[2],
                         width=100,
                         height=100)
# Get Highway Data from OSM
q <- opq(st_bbox(roads_box)) %>%
  add_osm_feature(key = "highway")
res <- osmdata_sf(q = q)
hw_lines <- st_coordinates(res$osm_lines)[,1:2]
rho <- function(par){
  distance <- dist2Line(c(par[1],par[2]), hw_lines)
  proper.distance <- distance[1] * 3.28084
  return(proper.distance)
}
logprior_road <- function (params) {
  point <- params[1:2]
  sigma <- params[3]
  dnorm(rho(point), mean=0, sd=6, log=T) + dexp(sigma, 15, log=T)
}
```
Using the same locations and bearings as above, we will move to the other model discussed in the methodology, in which we use a prior distribution which assumed the observer is on a road. Consider the case where the civil servant has left the building via an exit they don't recognise and is once again trying to figure out where they are.

As discussed in the methodology, we will use the same loglikelihood function, proposal distribution and initial value for the Metropolis-Hasting algorithm.  Although it may have been necessary, no changes to covariance matrix of the proposal algorithm were required. As before, we will begin measuring the Gelman-Rubin statistic for all parameters after 2,000 iterations. This produces the following traceplots.

```{r roads-convergence-traceplots, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.height='120%', out.width='110%'}
#now using these alongside existing loglikelihood to run M-H
draws <- array(0,dim=c(50000,3,3))
draws[50000,1,] <- runif(3,intersection[1]-0.01, intersection[1]+0.01)
draws[50000,2,] <- runif(3,intersection[2]-0.01, intersection[2]+0.01)
draws[50000,3,] <- rexp(3,20)

#evaluate posterior by sampling using M-H algorithm
converged <- FALSE
step <- 2
accepted <- rep(1,3)
prop.cov <- c(1e-8,1e-8,1e-4)*diag(3) #beginning with arbitrary proposal
while (!all(converged)) {
  draws[1,,] <- draws[50000,,]
  for (chain in 1:3) {
    proposed <- c(0,0,-1)
    while (proposed[3] < 0) {
      proposed <- rmvnorm(1,draws[step-1,,chain],prop.cov)
    }
    r <- loglikelihood(proposed) + 
      logprior_road(proposed) +
      dtmvnorm(x=draws[step-1,,chain], mean=c(proposed), sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T) -
      loglikelihood(draws[step-1,,chain]) - 
      logprior_road(draws[step-1,,chain]) -
      dtmvnorm(x=proposed, mean=draws[step-1,,chain], sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T)
    a <- min(0,r)
    u <- runif(1)
    if (log(u) < a) {
      draws[step,,chain] <- proposed
      accepted[chain] <- accepted[chain]+1
    } else {
      draws[step,,chain] <- draws[step-1,,chain]
    }
  }
  step <- step + 1
  if (step > 2000) {
    chainlist <- mcmc.list(Chain1=mcmc(draws[,,1]),
                           Chain2=mcmc(draws[,,2]),
                           Chain3=mcmc(draws[,,3]))
    converged <- all((gelman.diag(chainlist)$psrf[,2])<1.2)
  }
}

#check convergence using traceplots
par(mfrow=c(3,1))
min_lamda=min(draws[1:(step-2),1,])
max_lambda=max(draws[1:(step-2),1,])
plot(1:(step-2),draws[1:(step-2),1,1],type="l",col=2,
     ylim=c(min_lamda,max_lambda), main="Traceplots of Longitude",
     xlab="Iteration", ylab="Longitude Sample")
lines(x=1:(step-2),y=draws[1:(step-2),1,2],col=3)
lines(1:(step-2),draws[1:(step-2),1,3],col=4)
min_phi=min(draws[1:(step-2),2,])
max_phi=max(draws[1:(step-2),2,])
plot(1:(step-2),draws[1:(step-2),2,1],type="l",col=2,
     ylim=c(min_phi,max_phi), main="Traceplots of Latitude",
     xlab="Iteration", ylab="Latitude Sample")
lines(1:(step-2),draws[1:(step-2),2,2],col=3)
lines(1:(step-2),draws[1:(step-2),2,3],col=4)
min_sigma=min(draws[1:(step-2),3,])
max_sigma=max(draws[1:(step-2),3,])
plot(1:(step-2),draws[1:(step-2),3,1],type="l",col=2,
     ylim=c(min_sigma,max_sigma), main="Traceplots of Standard Deviation",
     xlab="Iteration", ylab="SD Sample")
lines(1:(step-2),draws[1:(step-2),3,2],col=3)
lines(1:(step-2),draws[1:(step-2),3,3],col=4)
```

In addition to the Gelman-Rubin statistic, there is clear visual convergence for latitude and longitude, and somewhat visual convergence for the standard deviation. Using the final values from these chains, we initialise another run of Metropolis-Hasting for 25,000 samples of each chain. This generates the following traceplots.

```{r roads-sample-traceplots, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.height='120%', out.width='110%'}
sampler <- array(0,dim=c(25000,3,3))
sampler[1,,] <- draws[step-2,,]
accepted <- rep(1,3)
for (step in 2:25000) {
  for (chain in 1:3) {
    proposed <- c(0,0,-1)
    while (proposed[3] < 0) {
      proposed <- rmvnorm(1,sampler[step-1,,chain],prop.cov)
    }
    r <- loglikelihood(proposed) + 
      logprior_road(proposed) +
      dtmvnorm(x=sampler[step-1,,chain], mean=c(proposed), sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T) -
      loglikelihood(sampler[step-1,,chain]) - 
      logprior_road(sampler[step-1,,chain]) -
      dtmvnorm(x=proposed, mean=sampler[step-1,,chain], sigma=prop.cov, 
               lower=c(-Inf,-Inf,0), log=T)
    a <- min(0,r)
    u <- runif(1)
    if (log(u) < a) {
      sampler[step,,chain] <- proposed
      accepted[chain] <- accepted[chain]+1
    } else {
      sampler[step,,chain] <- sampler[step-1,,chain]
    }
  }
}
#plot chains to check we plotted those with convergence
par(mfrow=c(3,1))
min_lambda=min(sampler[1:(step-1),1,])
max_lambda=max(sampler[1:(step-1),1,])
plot(1:(step-1),sampler[1:(step-1),1,1],type="l",col=2,
     ylim=c(min_lambda,max_lambda), main="Traceplots of Longitude",
     xlab="Iteration", ylab="Longitude Sample")
lines(1:(step-1),sampler[1:(step-1),1,2],col=3)
lines(1:(step-1),sampler[1:(step-1),1,3],col=4)
min_phi=min(sampler[1:(step-1),2,])
max_phi=max(sampler[1:(step-1),2,])
plot(1:(step-1),sampler[1:(step-1),2,1],type="l",col=2,
     ylim=c(min_phi,max_phi), main="Traceplots of Latitude",
     xlab="Iteration", ylab="Latitude Sample")
lines(1:(step-1),sampler[1:(step-1),2,2],col=3)
lines(1:(step-1),sampler[1:(step-1),2,3],col=4)
min_sigma=min(sampler[1:(step-1),3,])
max_sigma=max(sampler[1:(step-1),3,])
plot(1:(step-1),sampler[1:(step-1),3,1],type="l",col=2,
     ylim=c(min_sigma,max_sigma), main="Traceplots of Standard Deviation",
     xlab="Iteration", ylab="SD Sample")
lines(1:(step-1),sampler[1:(step-1),3,2],col=3)
lines(1:(step-1),sampler[1:(step-1),3,3],col=4)
```

The acceptance rates are in an adequate range and the traceplots of latitude and longitude look good. Although when compared to the first example they may visually look to have worrying low acceptance rates, this is a side effect of the smaller number of iterations required for these chains. The traceplot of the standard deviation is disappointing, but without dedicating several hours of computing power, it would be difficult to improve this and as it's output is less key to our interests it can be disregarded.

From these we can judge that the chains have converged and begin analysing their values. As before, the first step is to look at the histograms of the latitude and longitude sample values.

```{r roads-hist, echo=FALSE}
#also looking at the histograms
par(mfrow=c(1,2))
hist(sampler[,1,], main="Histogram of Longitude", xlab="Value", ylab="")
hist(sampler[,2,], main="Histogram of Latitude", xlab="Value", ylab="")
```
These seem to centre on the values we are expecting and once again these are not symmetrical. In this case the factor effecting the samples are more complex than before meaning this isn't surprising.

Finally we plot these values on a map. These samples are clearly shifted from the previous area toward the road at the top of the triangle and are focused around a smaller area.

```{r roads-map, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width='70%'}
#plotting the lambda and theta coordinate estimates
Dr <- kde2d(as.vector(sampler[,1,]),as.vector(sampler[,2,]),
           h=c(sd(sampler[,1,]),sd(sampler[,2,])),
           n=1024,
           lims=c(-0.14,-0.12,51.504,51.507)) # Enough to cover map
zr <- melt(Dr$z)
zr$Var1<-Dr$x[zr$Var1]
zr$Var2<-Dr$y[zr$Var2]
mapr <- get_map(c(mean(sampler[,1,]),mean(sampler[,2,])),zoom=18,maptype="road")
mapPoints_road <- ggmap(mapr)+
  geom_point(aes(x = lon, y = lat), size = 1, 
             data=landmarks,alpha=.5) +
  geom_raster(data=z,aes(x=Var1,y=Var2,fill=value))+
  guides(fill="none",alpha="none")+
  scale_fill_gradientn(colours=c("#0000FF00","#0000FFFF"))+
  coord_cartesian() +
  geom_line(aes(x=lon,y=lat),data=line1) +
  geom_line(aes(x=lon,y=lat),data=line2) +
  geom_line(aes(x=lon,y=lat),data=line3)+
  geom_point(aes(x=lon,y=lat),
             data=data.frame(lon=mean(sampler[,1,]),lat=mean(sampler[,2,])),
             size=0.5,colour="#FF0000")
mapPoints_road
```



## Conclusions

This has report has worked through two examples of Metropolis-Hasting algorithm implementation and considered the differences between uniform and more informed prior distributions. As expected, using a prior distribution that contained more pre-existing knowledge gave a less widely-distribution and clearer pattern of our observers location.

That said, looking again at our original map, an intuitive assumption might be that the observation was taken from a location high enough to see the landmarks that bearings were taken of. Although there are datasets of altitude there is no comparative dataset of maximum heights of structures. Despite this, an enquiring mind may well look at the original map and note that there is a domed structure within the triangle from which the landmarks observed are likely to have been visible. They may well deduce that this was where the observations were taken from, and would be correct.

In our example, the alternative prior distribution focused on proximity to roads, this was a convenient example but isn't reflective of where the obervations were actually taken. In this case, any possible computational analysis, including Bayesian, is limited by the availability of data. In this case, a royal marines sarge may well have been able to more accurately and more quickly locate the observer than either of the examples above.


## References

^1^ ORDINANCE SURVEY, 2020. ADVANCED GUIDE TO PINPOINTING YOUR LOCATION [online]. Ordinance Survey. [viewed 03 December 2021]. Available from: https://getoutside.ordnancesurvey.co.uk/guides/navigation-pinpointing-your-location/

